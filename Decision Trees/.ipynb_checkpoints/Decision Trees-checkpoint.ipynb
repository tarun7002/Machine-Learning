{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Decision Trees from scratch using ID3 algorithm\n",
    "## Project to classify people with different income groups\n",
    "### - by Vinay Kumar Ranganath Babu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age          workclass  fnlwgt   education  education_num  \\\n",
      "0   39          State-gov   77516   Bachelors             13   \n",
      "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
      "2   38            Private  215646     HS-grad              9   \n",
      "3   53            Private  234721        11th              7   \n",
      "4   28            Private  338409   Bachelors             13   \n",
      "\n",
      "        marital_status          occupation    relationship    race      sex  \\\n",
      "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
      "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
      "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
      "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
      "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
      "\n",
      "   capital_gain  capital_loss  hours_per_week  native_country high_income  \n",
      "0          2174             0              40   United-States       <=50K  \n",
      "1             0             0              13   United-States       <=50K  \n",
      "2             0             0              40   United-States       <=50K  \n",
      "3             0             0              40   United-States       <=50K  \n",
      "4             0             0              40            Cuba       <=50K  \n",
      "Index(['age', 'workclass', 'fnlwgt', 'education', 'education_num',\n",
      "       'marital_status', 'occupation', 'relationship', 'race', 'sex',\n",
      "       'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
      "       'high_income'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set index_col to False to avoid pandas thinking that the first column is row indexes (it's age).\n",
    "income = pd.read_csv(\"income.data\", index_col=False)\n",
    "print(income.head(5))\n",
    "print(income.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    7\n",
      "1    6\n",
      "2    4\n",
      "3    4\n",
      "4    4\n",
      "Name: workclass, dtype: int8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinay\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:2: FutureWarning: Categorical.from_array is deprecated, use Categorical instead\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\vinay\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:6: FutureWarning: Categorical.from_array is deprecated, use Categorical instead\n"
     ]
    }
   ],
   "source": [
    "# Convert a single column from text categories into numbers.\n",
    "col = pd.Categorical.from_array(income[\"workclass\"])\n",
    "income[\"workclass\"] = col.codes\n",
    "print(income[\"workclass\"].head(5))\n",
    "for name in [\"education\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native_country\", \"high_income\"]:\n",
    "    col = pd.Categorical.from_array(income[name])\n",
    "    income[name] = col.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing A Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22696, 15)\n",
      "(9865, 15)\n"
     ]
    }
   ],
   "source": [
    "private_incomes = income[income[\"workclass\"] == 4]\n",
    "public_incomes = income[income[\"workclass\"] != 4]\n",
    "\n",
    "print(private_incomes.shape)\n",
    "print(public_incomes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9709505944546686\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "# Passing 2 as the second parameter to math.log will take a base 2 log.\n",
    "entropy = -(2/5 * math.log(2/5, 2) + 3/5 * math.log(3/5, 2))\n",
    "print(entropy)\n",
    "prob_0 = income[income[\"high_income\"] == 0].shape[0] / income.shape[0]\n",
    "prob_1 = income[income[\"high_income\"] == 1].shape[0] / income.shape[0]\n",
    "income_entropy = -(prob_0 * math.log(prob_0, 2) + prob_1 * math.log(prob_1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def calc_entropy(column):\n",
    "    \"\"\"\n",
    "    Calculate entropy given a pandas Series, list, or numpy array.\n",
    "    \"\"\"\n",
    "    # Compute the counts of each unique value in the column.\n",
    "    counts = numpy.bincount(column)\n",
    "    # Divide by the total column length to get a probability.\n",
    "    probabilities = counts / len(column)\n",
    "    \n",
    "    # Initialize the entropy to 0.\n",
    "    entropy = 0\n",
    "    # Loop through the probabilities, and add each one to the total entropy.\n",
    "    for prob in probabilities:\n",
    "        if prob > 0:\n",
    "            entropy += prob * math.log(prob, 2)\n",
    "    \n",
    "    return -entropy\n",
    "\n",
    "income_entropy = calc_entropy(income[\"high_income\"])\n",
    "\n",
    "median_age = income[\"age\"].median()\n",
    "\n",
    "left_split = income[income[\"age\"] <= median_age]\n",
    "right_split = income[income[\"age\"] > median_age]\n",
    "\n",
    "age_information_gain = income_entropy - ((left_split.shape[0] / income.shape[0]) * \n",
    "                                         calc_entropy(left_split[\"high_income\"]) + \n",
    "                                         ((right_split.shape[0] / income.shape[0]) * \n",
    "                                          calc_entropy(right_split[\"high_income\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding The Best Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0470286613047\n"
     ]
    }
   ],
   "source": [
    "def calc_information_gain(data, split_name, target_name):\n",
    "    \"\"\"\n",
    "    Calculate information gain given a dataset, column to split on, and target.\n",
    "    \"\"\"\n",
    "    # Calculate original entropy.\n",
    "    original_entropy = calc_entropy(data[target_name])\n",
    "    \n",
    "    # Find the median of the column we're splitting.\n",
    "    column = data[split_name]\n",
    "    median = column.median()\n",
    "    \n",
    "    # Make two subsets of the data based on the median.\n",
    "    left_split = data[column <= median]\n",
    "    right_split = data[column > median]\n",
    "    \n",
    "    # Loop through the splits, and calculate the subset entropy.\n",
    "    to_subtract = 0\n",
    "    for subset in [left_split, right_split]:\n",
    "        prob = (subset.shape[0] / data.shape[0]) \n",
    "        to_subtract += prob * calc_entropy(subset[target_name])\n",
    "    \n",
    "    # Return information gain.\n",
    "    return original_entropy - to_subtract\n",
    "\n",
    "# Verify that our answer \n",
    "print(calc_information_gain(income, \"age\", \"high_income\"))\n",
    "\n",
    "columns = [\"age\", \"workclass\", \"education_num\", \"marital_status\", \"occupation\", \"relationship\", \n",
    "           \"race\", \"sex\", \"hours_per_week\", \"native_country\"]\n",
    "information_gains = []\n",
    "# Loop through and compute information gains.\n",
    "for col in columns:\n",
    "    information_gain = calc_information_gain(income, col, \"high_income\")\n",
    "    information_gains.append(information_gain)\n",
    "\n",
    "# Find the name of the column with the highest gain.\n",
    "highest_gain_index = information_gains.index(max(information_gains))\n",
    "highest_gain = columns[highest_gain_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column Split Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A list of columns to potentially split income with.\n",
    "columns = [\"age\", \"workclass\", \"education_num\", \"marital_status\", \"occupation\", \"relationship\", \n",
    "           \"race\", \"sex\", \"hours_per_week\", \"native_country\"]\n",
    "\n",
    "def find_best_column(data, target_name, columns):\n",
    "    information_gains = []\n",
    "    # Loop through and compute information gains.\n",
    "    for col in columns:\n",
    "        information_gain = calc_information_gain(data, col, \"high_income\")\n",
    "        information_gains.append(information_gain)\n",
    "\n",
    "    # Find the name of the column with the highest gain.\n",
    "    highest_gain_index = information_gains.index(max(information_gains))\n",
    "    highest_gain = columns[highest_gain_index]\n",
    "    return highest_gain\n",
    "\n",
    "income_split = find_best_column(income, \"high_income\", columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID3 algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "id3() missing 1 required positional argument: 'tree'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-8f9d4e66dd7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[1;31m# Call the function on our data to set the counters properly.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mid3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"high_income\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"age\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"marital_status\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mlabel_1s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mlabel_0s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: id3() missing 1 required positional argument: 'tree'"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import math\n",
    "\n",
    "# Set a random seed so the shuffle is the same every time.\n",
    "numpy.random.seed(1)\n",
    "\n",
    "# Shuffle the rows.  This first permutes the index randomly using numpy.random.permutation.\n",
    "# Then, it reindexes the dataframe with this.\n",
    "# The net effect is to put the rows into random order.\n",
    "income = income.reindex(numpy.random.permutation(income.index))\n",
    "\n",
    "train_max_row = math.floor(income.shape[0] * .8)\n",
    "train = income.iloc[:train_max_row]\n",
    "test = income.iloc[train_max_row:]\n",
    "\n",
    "# Create the dataset that we used in the example in the last screen.\n",
    "data = pd.DataFrame([\n",
    "    [0,20,0],\n",
    "    [0,60,2],\n",
    "    [0,40,1],\n",
    "    [1,25,1],\n",
    "    [1,35,2],\n",
    "    [1,55,1]\n",
    "    ])\n",
    "# Assign column names to the data.\n",
    "data.columns = [\"high_income\", \"age\", \"marital_status\"]\n",
    "\n",
    "# Call the function on our data to set the counters properly.\n",
    "id3(data, \"high_income\", [\"age\", \"marital_status\"])\n",
    "label_1s = []\n",
    "label_0s = []\n",
    "\n",
    "def id3(data, target, columns):\n",
    "    unique_targets = pd.unique(data[target])\n",
    "\n",
    "    if len(unique_targets) == 1:\n",
    "        if 0 in unique_targets:\n",
    "            label_0s.append(0)\n",
    "        elif 1 in unique_targets:\n",
    "            label_1s.append(1)\n",
    "        return\n",
    "    \n",
    "    best_column = find_best_column(data, target, columns)\n",
    "    column_median = data[best_column].median()\n",
    "    \n",
    "    left_split = data[data[best_column] <= column_median]\n",
    "    right_split = data[data[best_column] > column_median]\n",
    "    \n",
    "    for split in [left_split, right_split]:\n",
    "        id3(split, target, columns)\n",
    "\n",
    "\n",
    "id3(data, \"high_income\", [\"age\", \"marital_status\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing The Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Call the function on our data to set the counters properly.\n",
    "id3(data, \"high_income\", [\"age\", \"marital_status\"], tree)\n",
    "tree = {}\n",
    "nodes = []\n",
    "\n",
    "def id3(data, target, columns, tree):\n",
    "    unique_targets = pd.unique(data[target])\n",
    "    nodes.append(len(nodes) + 1)\n",
    "    tree[\"number\"] = nodes[-1]\n",
    "\n",
    "    if len(unique_targets) == 1:\n",
    "        if 0 in unique_targets:\n",
    "            tree[\"label\"] = 0\n",
    "        elif 1 in unique_targets:\n",
    "            tree[\"label\"] = 1\n",
    "        return\n",
    "    \n",
    "    best_column = find_best_column(data, target, columns)\n",
    "    column_median = data[best_column].median()\n",
    "    \n",
    "    tree[\"column\"] = best_column\n",
    "    tree[\"median\"] = column_median\n",
    "    \n",
    "    left_split = data[data[best_column] <= column_median]\n",
    "    right_split = data[data[best_column] > column_median]\n",
    "    split_dict = [[\"left\", left_split], [\"right\", right_split]]\n",
    "    \n",
    "    for name, split in split_dict:\n",
    "        tree[name] = {}\n",
    "        id3(split, target, columns, tree[name])\n",
    "\n",
    "\n",
    "id3(data, \"high_income\", [\"age\", \"marital_status\"], tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prettier Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age > 37.5\n",
      "    age > 25.0\n",
      "        age > 22.5\n",
      "            Leaf: Label 0\n",
      "            Leaf: Label 1\n",
      "        Leaf: Label 1\n",
      "    age > 55.0\n",
      "        age > 47.5\n",
      "            Leaf: Label 0\n",
      "            Leaf: Label 1\n",
      "        Leaf: Label 0\n"
     ]
    }
   ],
   "source": [
    "def print_with_depth(string, depth):\n",
    "    # Add space before a string.\n",
    "    prefix = \"    \" * depth\n",
    "    # Print a string, appropriately indented.\n",
    "    print(\"{0}{1}\".format(prefix, string))\n",
    "    \n",
    "    \n",
    "def print_node(tree, depth):\n",
    "    if \"label\" in tree:\n",
    "        print_with_depth(\"Leaf: Label {0}\".format(tree[\"label\"]), depth)\n",
    "        return\n",
    "    print_with_depth(\"{0} > {1}\".format(tree[\"column\"], tree[\"median\"]), depth)\n",
    "    for branch in [tree[\"left\"], tree[\"right\"]]:\n",
    "        print_node(branch, depth+1)\n",
    "\n",
    "print_node(tree, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "def predict(tree, row):\n",
    "    if \"label\" in tree:\n",
    "        return tree[\"label\"]\n",
    "    \n",
    "    column = tree[\"column\"]\n",
    "    median = tree[\"median\"]\n",
    "    if row[column] <= median:\n",
    "        return predict(tree[\"left\"], row)\n",
    "    else:\n",
    "        return predict(tree[\"right\"], row)\n",
    "\n",
    "print(predict(tree, data.iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_data = pd.DataFrame([\n",
    "    [40,0],\n",
    "    [20,2],\n",
    "    [80,1],\n",
    "    [15,1],\n",
    "    [27,2],\n",
    "    [38,1]\n",
    "    ])\n",
    "# Assign column names to the data.\n",
    "new_data.columns = [\"age\", \"marital_status\"]\n",
    "\n",
    "def batch_predict(tree, df):\n",
    "    return df.apply(lambda x: predict(tree, x), axis=1)\n",
    "\n",
    "predictions = batch_predict(tree, new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    1\n",
       "5    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using sklearn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=1, splitter='best')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# A list of columns to train with.\n",
    "# All columns have been converted to numeric.\n",
    "columns = [\"age\", \"workclass\", \"education_num\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"hours_per_week\", \"native_country\"]\n",
    "\n",
    "# Instantiate the classifier.\n",
    "# Set random_state to 1 to keep results consistent.\n",
    "clf = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# The variable income is loaded, and contains all the income data.\n",
    "clf.fit(income[columns], income[\"high_income\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import math\n",
    "\n",
    "# Set a random seed so the shuffle is the same every time.\n",
    "numpy.random.seed(1)\n",
    "\n",
    "# Shuffle the rows.  This first permutes the index randomly using numpy.random.permutation.\n",
    "# Then, it reindexes the dataframe with this.\n",
    "# The net effect is to put the rows into random order.\n",
    "income = income.reindex(numpy.random.permutation(income.index))\n",
    "\n",
    "train_max_row = math.floor(income.shape[0] * .8)\n",
    "train = income.iloc[:train_max_row]\n",
    "test = income.iloc[train_max_row:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.68660927897\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=1)\n",
    "clf.fit(train[columns], train[\"high_income\"])\n",
    "\n",
    "predictions = clf.predict(test[columns])\n",
    "error = roc_auc_score(test[\"high_income\"], predictions)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Error On The Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.950831270345\n"
     ]
    }
   ],
   "source": [
    "predictions = clf.predict(train[columns])\n",
    "print(roc_auc_score(train[\"high_income\"], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building A Shallower Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.70019484674\n",
      "0.840934791195\n"
     ]
    }
   ],
   "source": [
    "# Decision trees model from the last screen.\n",
    "clf = DecisionTreeClassifier(random_state=1)\n",
    "clf = DecisionTreeClassifier(min_samples_split=13, random_state=1)\n",
    "clf.fit(train[columns], train[\"high_income\"])\n",
    "predictions = clf.predict(test[columns])\n",
    "test_auc = roc_auc_score(test[\"high_income\"], predictions)\n",
    "\n",
    "train_predictions = clf.predict(train[columns])\n",
    "train_auc = roc_auc_score(train[\"high_income\"], train_predictions)\n",
    "\n",
    "print(test_auc)\n",
    "print(train_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tweaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.68660927897\n",
      "0.950831270345\n",
      "0.737654665659\n",
      "0.751899955574\n"
     ]
    }
   ],
   "source": [
    "# First decision trees model we trained and tested.\n",
    "clf = DecisionTreeClassifier(random_state=1)\n",
    "clf.fit(train[columns], train[\"high_income\"])\n",
    "predictions = clf.predict(test[columns])\n",
    "test_auc = roc_auc_score(test[\"high_income\"], predictions)\n",
    "\n",
    "train_predictions = clf.predict(train[columns])\n",
    "train_auc = roc_auc_score(train[\"high_income\"], train_predictions)\n",
    "\n",
    "print(test_auc)\n",
    "print(train_auc)\n",
    "clf = DecisionTreeClassifier(random_state=1, min_samples_split=13, max_depth=7)\n",
    "clf.fit(train[columns], train[\"high_income\"])\n",
    "predictions = clf.predict(test[columns])\n",
    "test_auc = roc_auc_score(test[\"high_income\"], predictions)\n",
    "\n",
    "train_predictions = clf.predict(train[columns])\n",
    "train_auc = roc_auc_score(train[\"high_income\"], train_predictions)\n",
    "\n",
    "print(test_auc)\n",
    "print(train_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweaking The Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.68660927897\n",
      "0.950831270345\n",
      "0.658183369201\n",
      "0.661642868779\n"
     ]
    }
   ],
   "source": [
    "# First decision trees model we trained and tested.\n",
    "clf = DecisionTreeClassifier(random_state=1)\n",
    "clf.fit(train[columns], train[\"high_income\"])\n",
    "predictions = clf.predict(test[columns])\n",
    "test_auc = roc_auc_score(test[\"high_income\"], predictions)\n",
    "\n",
    "train_predictions = clf.predict(train[columns])\n",
    "train_auc = roc_auc_score(train[\"high_income\"], train_predictions)\n",
    "\n",
    "print(test_auc)\n",
    "print(train_auc)\n",
    "clf = DecisionTreeClassifier(random_state=1, min_samples_split=100, max_depth=2)\n",
    "clf.fit(train[columns], train[\"high_income\"])\n",
    "predictions = clf.predict(test[columns])\n",
    "test_auc = roc_auc_score(test[\"high_income\"], predictions)\n",
    "\n",
    "train_predictions = clf.predict(train[columns])\n",
    "train_auc = roc_auc_score(train[\"high_income\"], train_predictions)\n",
    "\n",
    "print(test_auc)\n",
    "print(train_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Decision Tree Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.685969677582\n",
      "0.976554275087\n"
     ]
    }
   ],
   "source": [
    "numpy.random.seed(1)\n",
    "\n",
    "# Generate a column with random numbers from 0 to 4.\n",
    "income[\"noise\"] = numpy.random.randint(4, size=income.shape[0])\n",
    "\n",
    "# Adjust columns to include the noise column.\n",
    "columns = [\"noise\", \"age\", \"workclass\", \"education_num\", \"marital_status\", \"occupation\", \n",
    "           \"relationship\", \"race\", \"sex\", \"hours_per_week\", \"native_country\"]\n",
    "\n",
    "# Make new train and test sets.\n",
    "train_max_row = math.floor(income.shape[0] * .8)\n",
    "train = income.iloc[:train_max_row]\n",
    "test = income.iloc[train_max_row:]\n",
    "\n",
    "# Initialize the classifier.\n",
    "clf = DecisionTreeClassifier(random_state=1)\n",
    "clf.fit(train[columns], train[\"high_income\"])\n",
    "predictions = clf.predict(test[columns])\n",
    "test_auc = roc_auc_score(test[\"high_income\"], predictions)\n",
    "\n",
    "train_predictions = clf.predict(train[columns])\n",
    "train_auc = roc_auc_score(train[\"high_income\"], train_predictions)\n",
    "\n",
    "print(test_auc)\n",
    "print(train_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
